# MPRG - Multi-Path Reasoning Guard

A safety gate that validates agentic workflows by checking whether **multiple distinct reasoning families** support a plan or answer â€” not just surface-level agreement.

## ğŸ”‘ Core Concept

Before an agent acts, MPRG checks if there are **different reasoning paths** behind the output, not just multiple agents saying the same thing.

## âœ… What This Build Includes

- Parallel multi-agent runs (3â€“5 roles) with strict JSON ReasoningSummary outputs
- Validation + retry (JSON-only on failure)
- Reasoning family clustering with:
  - plan embedding cosine similarity
  - assumption overlap (Jaccard)
- Robustness status:
  - 1 family â†’ FRAGILE
  - 2+ families â†’ ROBUST
- MongoDB Atlas as system-of-record (tasks, runs, families)
- Restart-safe clustering (resume from stored runs)
- Minimal API + demo UI

## âš¡ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
cp .env.example .env

# Required
OPENAI_API_KEY=your_openai_key_here
MONGODB_URI=mongodb+srv://<username>:<password>@<cluster>.mongodb.net/mprg?retryWrites=true&w=majority

# Optional overrides
OPENAI_MODEL=gpt-4o-mini
AGENT_COUNT=4
PLAN_SIM_THRESHOLD=0.85
ASSUMPTION_SIM_THRESHOLD=0.70
```

### 3. Run the Server

```bash
python server.py
```

### 4. Open Demo UI

Open `web/index.html` in your browser.

## ğŸ§© Reasoning Guard Generator (Standalone)

This module runs diverse agents and returns a JSON TaskBundle without touching MongoDB.

```bash
python generator_server.py
```

POST to `/generate`:

```json
{
  "user_prompt": "Plan a 3-hour workflow to sync data across APIs."
}
```

Response: `TaskBundle` with `runs[]` including strict `ReasoningSummary` JSON.

### Using Anthropic Instead of OpenAI

Set the provider and key in `.env`:

```
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=your_anthropic_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20240620
ANTHROPIC_API_BASE=https://api.anthropic.com
```

Install the SDK:

```bash
pip install anthropic
```

## ğŸ“¡ API

- `POST /tasks`
  - Body: `{ "task": "Your task prompt" }`
  - Response: `{ "task_id": "..." }`
- `GET /tasks/:id`
  - Task status + robustness metrics
- `GET /tasks/:id/runs`
  - Raw agent runs (ReasoningSummary + validity)
- `GET /tasks/:id/families`
  - Reasoning families + representative signatures

## ğŸ—„ï¸ MongoDB Collections

- `tasks`: task prompt, created_at, status, robustness metrics
- `runs`: agent outputs + ReasoningSummary + embeddings + validity
- `families`: clustering results + family signature + robustness metrics

## ğŸ“ Project Structure

```
agentpathing/
â”œâ”€â”€ server.py             # Flask API
â”œâ”€â”€ mprg/
â”‚   â”œâ”€â”€ agent_runner.py   # Multi-agent LLM runner (JSON enforced)
â”‚   â”œâ”€â”€ models.py         # ReasoningSummary schema + validation
â”‚   â”œâ”€â”€ embeddings.py     # Plan embeddings + cosine similarity
â”‚   â”œâ”€â”€ cluster.py        # Family clustering logic
â”‚   â”œâ”€â”€ orchestrator.py   # End-to-end orchestration + resume
â”‚   â””â”€â”€ store.py          # MongoDB persistence
â””â”€â”€ web/
    â””â”€â”€ index.html        # Demo UI
```

## ğŸ§ª Demo Flow

1. Enter a task prompt in the UI
2. Watch 3â€“5 agent runs execute in parallel
3. MPRG clusters reasoning families
4. See robustness status + answer agreement

## ğŸ“œ License

MIT (or your preferred open-source license).
